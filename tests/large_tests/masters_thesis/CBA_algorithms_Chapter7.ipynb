{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we implement the four CBA prediction algorithms discussed in Chapter 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Data_preparation.ipynb\n",
      "importing Jupyter notebook from Classes.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# the data sets are prepared in another file\n",
    "import Data_preparation as d\n",
    "\n",
    "# the objects Case, Feature and CB are defined in another file\n",
    "from Classes import Case, Feature, CB, W_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of important features\n",
    "important_mushroom = ['odor_a', 'odor_c', 'odor_f', 'odor_l', 'odor_n', 'odor_p', 'gill-size_b', 'gill-size_n', \n",
    "        'gill-color_b', 'stalk-surface-above-ring_k', 'stalk-surface-below-ring_y', 'ring-type_f', 'spore-print-color_k', \n",
    "                      'spore-print-color_n', 'spore-print-color_r', 'spore-print-color_u', 'population_c']\n",
    "\n",
    "important_churn = ['tenure', 'OnlineSecurity', 'TotalCharges', 'Churn', 'Internet_sevice',\n",
    "       'InternetService_Fiber optic', 'InternetService_No',\n",
    "       'Contract_Month-to-month', 'Contract_Two year']\n",
    "\n",
    "important_admission = ['GRE Score', 'TOEFL Score', 'LOR ', 'CGPA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given training data and the label name, returns the feature weights\n",
    "def log_regression(train, y_name):\n",
    "    X_train = train.drop([y_name], axis=1)\n",
    "    y_train = train[y_name].astype('int')\n",
    "    \n",
    "    model = LogisticRegression(solver = 'lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receives a dataset, name of the outcome variables and the weights\n",
    "# returns a test and train case base and the weights\n",
    "def data_to_cb(data, y_name, important):\n",
    "    # remove unimportant features\n",
    "    columns = list(data.columns)\n",
    "    columns.remove(y_name)\n",
    "    for col in columns:\n",
    "        if col not in important:\n",
    "            del data[col]\n",
    "            columns.remove(col)\n",
    "\n",
    "    # split the data into 20% test and 80% training data\n",
    "    test_size = round(0.2 * len(data))\n",
    "    test = data.iloc[0:test_size,:]\n",
    "    train = data.iloc[test_size:,:]\n",
    "    \n",
    "    # create a dictionary with the normalized weights of the logistic regression\n",
    "    importance = log_regression(train, y_name)[0]\n",
    "    # normalize the importancies to range (-1, 1)\n",
    "    max_weight = max([abs(i) for i in importance])\n",
    "    importance = [round((i / max_weight), 2) for i in importance]\n",
    "    importance_dict = dict(zip(columns,importance))\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col != y_name:\n",
    "            # tendencies are established based on the weights\n",
    "            if importance_dict[col] > 0:\n",
    "                features.append(Feature(col, 1, False))\n",
    "            else:\n",
    "                features.append(Feature(col, 0, False))\n",
    "       \n",
    "    # the test and train set make up two different case bases\n",
    "    test_cb, train_cb = [], []\n",
    "    \n",
    "    # creating cases, triples Case(name, fact situation, outcome)\n",
    "    for data, cb in [[test, test_cb], [train, train_cb]]:\n",
    "        for i, row in data.iterrows():\n",
    "            outcome = row[y_name]\n",
    "\n",
    "            f_s = {}\n",
    "\n",
    "            for f in features:\n",
    "                f_s[f] = row[f.name]\n",
    "\n",
    "            cb.append(Case(i, f_s, outcome))\n",
    "        \n",
    "    return CB(test_cb), CB(train_cb), importance_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 1) priority + balance\n",
    "\n",
    "1. If there are precedents with no negative differences with the focus case\n",
    "    (a) Predict the most common outcome among these precedents\n",
    "2. Else\n",
    "    (a) Select all precedents with a maximal weighted balance (positive\n",
    "    differences - negative differences) with the focus case\n",
    "    (b) Predict the most common outcome among these precedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_priority(con_cb, test_cb, importance_dict, print_scores = False):\n",
    "    \n",
    "    n_correct = 0\n",
    "    \n",
    "    for focus in test_cb.cases:\n",
    "        comparisons, balances, best_comp, priority = [], [], [], []\n",
    "        for case in con_cb.cases:\n",
    "            com = focus.find_differences(case, importance_dict)\n",
    "            comparisons.append(com)\n",
    "            balances.append(com.balance)\n",
    "            if com.w_dif == 0:\n",
    "                priority.append(com)\n",
    "            \n",
    "        if len(priority) != 0:\n",
    "            best_comp = priority\n",
    "        else:\n",
    "            best_balance = sorted(balances)[-1]\n",
    "\n",
    "            for com in comparisons:\n",
    "                if com.balance == best_balance:\n",
    "                    best_comp.append(com)\n",
    "                \n",
    "        outcomes = []\n",
    "        for com in best_comp:\n",
    "            outcomes.append(com.case.outcome)\n",
    "        \n",
    "        prediction = max(outcomes, key = outcomes.count)\n",
    "        \n",
    "        if prediction == focus.outcome:\n",
    "            n_correct += 1\n",
    "    \n",
    "    return n_correct / test_cb.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 2) balance\n",
    "1. Select all precedents with a maximal weighted balance (positive differences - negative differences) with the focus case\n",
    "2. Predict the most common outcome among these precedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_balance(con_cb, test_cb, importance_dict, print_scores = False):\n",
    "    \n",
    "    n_correct = 0\n",
    "\n",
    "    for focus in test_cb.cases:\n",
    "        comparisons, balances, best_comp = [], [], []\n",
    "        for case in con_cb.cases:\n",
    "            com = focus.find_differences(case, importance_dict)\n",
    "            comparisons.append(com)\n",
    "            balances.append(com.balance)\n",
    "            \n",
    "        best_balance = sorted(balances)[-1]\n",
    "            \n",
    "        for com in comparisons:\n",
    "            if com.balance == best_balance:\n",
    "                best_comp.append(com)\n",
    "                \n",
    "        outcomes = []\n",
    "        for com in best_comp:\n",
    "            outcomes.append(com.case.outcome)\n",
    "        \n",
    "        prediction = max(outcomes, key = outcomes.count)\n",
    "        \n",
    "        if prediction == focus.outcome:\n",
    "            n_correct += 1\n",
    "\n",
    "    return n_correct / test_cb.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 3) minimize negative\n",
    "1. select all precedents with minimal weighted negative differences with the focus case\n",
    "2. predict the most common outcome among these precedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_min_negative(con_cb, test_cb, importance_dict, max_positive = 1, print_scores = False):\n",
    "    \n",
    "    n_correct = 0\n",
    "\n",
    "    for focus in test_cb.cases:\n",
    "        comparisons, negative, best_comp = [], [], []\n",
    "        for case in con_cb.cases:\n",
    "            com = focus.find_differences(case, importance_dict)\n",
    "            comparisons.append(com)\n",
    "            negative.append(com.w_dif)\n",
    "\n",
    "        best_worse = sorted(negative)[0]\n",
    "            \n",
    "        for com in comparisons:\n",
    "            if com.w_dif == best_worse:\n",
    "                best_comp.append(com)\n",
    "                \n",
    "        outcomes = []\n",
    "        for com in best_comp:\n",
    "            outcomes.append(com.case.outcome)\n",
    "        \n",
    "        prediction = max(outcomes, key = outcomes.count)\n",
    "        \n",
    "        if prediction == focus.outcome:\n",
    "            n_correct += 1\n",
    "\n",
    "    \n",
    "    return n_correct / test_cb.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 4) nearest neighbor\n",
    "1. select all precedents with minimal weighted differences (negative + positive) with the focus case\n",
    "2. predict the most common outcome among these precedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(con_cb, test_cb, importance_dict, print_scores = False):\n",
    "    \n",
    "    n_correct = 0\n",
    "\n",
    "    for focus in test_cb.cases:\n",
    "        differences, comparisons, best_comp = [], [], []\n",
    "        for case in con_cb.cases:\n",
    "            com = focus.find_differences(case, importance_dict)\n",
    "            comparisons.append(com)\n",
    "            differences.append(com.w_dif + com.b_dif)\n",
    "\n",
    "        best_dif = sorted(differences)[0]\n",
    "            \n",
    "        for com in comparisons:\n",
    "            if com.w_dif + com.b_dif == best_dif:\n",
    "                best_comp.append(com)\n",
    "                \n",
    "        outcomes = []\n",
    "        for com in best_comp:\n",
    "            outcomes.append(com.case.outcome)\n",
    "        \n",
    "        prediction = max(outcomes, key = outcomes.count)\n",
    "        \n",
    "        if prediction == focus.outcome:\n",
    "            n_correct += 1\n",
    "    \n",
    "    return n_correct / test_cb.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code to run a test\n",
    "def run_CBA_algorithms():\n",
    "\n",
    "    data, y_name, _, _ = d.get_churn()\n",
    "    # uses a small part of the data for illustration\n",
    "    test, train, importance_dict = data_to_cb(data.iloc[0:100,], y_name, important_churn)\n",
    "\n",
    "    print(test_balance(train, test, importance_dict))\n",
    "    print(test_min_negative(train, test, importance_dict))\n",
    "    print(test_nn(train, test, importance_dict))\n",
    "    print(test_priority(train, test, importance_dict))\n",
    "\n",
    "    # turn the training case base into a consistent one \n",
    "    con_train = train.make_consistent(1)\n",
    "\n",
    "    print(test_balance(con_train, test, importance_dict))\n",
    "    print(test_min_negative(con_train, test, importance_dict))\n",
    "    print(test_nn(con_train, test, importance_dict))\n",
    "    print(test_priority(con_train, test, importance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
